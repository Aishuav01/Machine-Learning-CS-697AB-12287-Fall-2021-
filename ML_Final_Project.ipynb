{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aishuav01/Machine-Learning-CS-697AB-12287-Fall-2021-/blob/main/ML_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_LnOH0-MIqd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR789oMeMNtx",
        "outputId": "9d864db7-0af9-42e0-cadc-a1548f39d639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XosdDfXSMUpG"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,\n",
        "                                                      test_size=5000)\n",
        "\n",
        "# Normalization\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid /255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0BVcXEPMaBp",
        "outputId": "18155ea1-fd55-467c-b5ad-c3a48e153498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 28, 20)       580         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 20)       80          dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 28, 30)       630         batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 30)       120         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 28, 58)       0           input_1[0][0]                    \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1624)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1624)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 15)           24375       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,785\n",
            "Trainable params: 25,685\n",
            "Non-trainable params: 100\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(20, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(30, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "concat = keras.layers.Concatenate()([input, bat2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.4)(flatten)\n",
        "output = keras.layers.Dense(15, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTC09P4GMdkL",
        "outputId": "bc673f68-61f6-4bf3-b27d-e029b30cb7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 3ms/step - loss: 0.7247 - accuracy: 0.7515 - val_loss: 0.3712 - val_accuracy: 0.8680\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4169 - accuracy: 0.8507 - val_loss: 0.3515 - val_accuracy: 0.8734\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3951 - accuracy: 0.8606 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3829 - accuracy: 0.8634 - val_loss: 0.3437 - val_accuracy: 0.8750\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3572 - accuracy: 0.8690 - val_loss: 0.3263 - val_accuracy: 0.8810\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3532 - accuracy: 0.8723 - val_loss: 0.3219 - val_accuracy: 0.8850\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3488 - accuracy: 0.8730 - val_loss: 0.3176 - val_accuracy: 0.8858\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3425 - accuracy: 0.8770 - val_loss: 0.3255 - val_accuracy: 0.8880\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3383 - accuracy: 0.8791 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3306 - accuracy: 0.8807 - val_loss: 0.3332 - val_accuracy: 0.8796\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3284 - accuracy: 0.8774 - val_loss: 0.2991 - val_accuracy: 0.8930\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3332 - accuracy: 0.8794 - val_loss: 0.3107 - val_accuracy: 0.8886\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3251 - accuracy: 0.8804 - val_loss: 0.2962 - val_accuracy: 0.8966\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3287 - accuracy: 0.8800 - val_loss: 0.2980 - val_accuracy: 0.8934\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8801 - val_loss: 0.2961 - val_accuracy: 0.8970\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3198 - accuracy: 0.8807 - val_loss: 0.3094 - val_accuracy: 0.8902\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3223 - accuracy: 0.8813 - val_loss: 0.2955 - val_accuracy: 0.8984\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3222 - accuracy: 0.8830 - val_loss: 0.3038 - val_accuracy: 0.8894\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3176 - accuracy: 0.8841 - val_loss: 0.2994 - val_accuracy: 0.8950\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3114 - accuracy: 0.8868 - val_loss: 0.3078 - val_accuracy: 0.8890\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3126 - accuracy: 0.8855 - val_loss: 0.3142 - val_accuracy: 0.8828\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3147 - accuracy: 0.8877 - val_loss: 0.2919 - val_accuracy: 0.8982\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3175 - accuracy: 0.8860 - val_loss: 0.2940 - val_accuracy: 0.8932\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3003 - accuracy: 0.8899 - val_loss: 0.2938 - val_accuracy: 0.8898\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3097 - accuracy: 0.8853 - val_loss: 0.2913 - val_accuracy: 0.8998\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3084 - accuracy: 0.8887 - val_loss: 0.2993 - val_accuracy: 0.8932\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3136 - accuracy: 0.8877 - val_loss: 0.3031 - val_accuracy: 0.8902\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3106 - accuracy: 0.8846 - val_loss: 0.2959 - val_accuracy: 0.8938\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3104 - accuracy: 0.8870 - val_loss: 0.2872 - val_accuracy: 0.8962\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3024 - accuracy: 0.8890 - val_loss: 0.2885 - val_accuracy: 0.8984\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVC3EsHTMfci",
        "outputId": "40f5e15c-88bb-4731-d27c-4aaf56a0943f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Acc:  88.82363438606262\n",
            "Validation Acc:  89.84000086784363\n",
            "Test Acc:  88.919997215271\n"
          ]
        }
      ],
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld4TwJ16Mjed",
        "outputId": "95980336-00f0-446b-c045-7b78f098eed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 28, 55)       1595        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 55)       220         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 28, 75)       4200        batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 75)       300         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 28, 103)      0           input_2[0][0]                    \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2884)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2884)         0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           28850       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 35,165\n",
            "Trainable params: 34,905\n",
            "Non-trainable params: 260\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(55, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(75, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "concat = keras.layers.Concatenate()([input, bat2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.5)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9eoE3jmMmul",
        "outputId": "7d66f2e9-b3b1-4522-bab8-4b460ac0a025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 0.7145 - accuracy: 0.7695 - val_loss: 0.3762 - val_accuracy: 0.8716\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4367 - accuracy: 0.8513 - val_loss: 0.3662 - val_accuracy: 0.8734\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3909 - accuracy: 0.8629 - val_loss: 0.3266 - val_accuracy: 0.8854\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3736 - accuracy: 0.8698 - val_loss: 0.3552 - val_accuracy: 0.8768\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3525 - accuracy: 0.8734 - val_loss: 0.3339 - val_accuracy: 0.8806\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3365 - accuracy: 0.8789 - val_loss: 0.3077 - val_accuracy: 0.8884\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3327 - accuracy: 0.8786 - val_loss: 0.3058 - val_accuracy: 0.8892\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3211 - accuracy: 0.8827 - val_loss: 0.3261 - val_accuracy: 0.8802\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3151 - accuracy: 0.8869 - val_loss: 0.3035 - val_accuracy: 0.8892\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3143 - accuracy: 0.8886 - val_loss: 0.2988 - val_accuracy: 0.8964\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3023 - accuracy: 0.8913 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3034 - accuracy: 0.8901 - val_loss: 0.2950 - val_accuracy: 0.8940\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2977 - accuracy: 0.8906 - val_loss: 0.2916 - val_accuracy: 0.8966\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2972 - accuracy: 0.8918 - val_loss: 0.3040 - val_accuracy: 0.8902\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2967 - accuracy: 0.8909 - val_loss: 0.2990 - val_accuracy: 0.8904\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2852 - accuracy: 0.8946 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2910 - accuracy: 0.8930 - val_loss: 0.2910 - val_accuracy: 0.8976\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2841 - accuracy: 0.8960 - val_loss: 0.2866 - val_accuracy: 0.8982\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2802 - accuracy: 0.8977 - val_loss: 0.3042 - val_accuracy: 0.8944\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2749 - accuracy: 0.8989 - val_loss: 0.2841 - val_accuracy: 0.9004\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2755 - accuracy: 0.9010 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2750 - accuracy: 0.9000 - val_loss: 0.2933 - val_accuracy: 0.9006\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2806 - accuracy: 0.8966 - val_loss: 0.2882 - val_accuracy: 0.8962\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2709 - accuracy: 0.9003 - val_loss: 0.2921 - val_accuracy: 0.8954\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2667 - accuracy: 0.9006 - val_loss: 0.3025 - val_accuracy: 0.8950\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2648 - accuracy: 0.9034 - val_loss: 0.3008 - val_accuracy: 0.8964\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2665 - accuracy: 0.9034 - val_loss: 0.2869 - val_accuracy: 0.9008\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2641 - accuracy: 0.9012 - val_loss: 0.2877 - val_accuracy: 0.9022\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2573 - accuracy: 0.9046 - val_loss: 0.2949 - val_accuracy: 0.8976\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2604 - accuracy: 0.9037 - val_loss: 0.2921 - val_accuracy: 0.8982\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im-OzSecMpqc",
        "outputId": "23d07638-40b6-48e0-8c4d-cd3b362b734b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Acc:  90.15454649925232\n",
            "Validation Acc:  89.819997549057\n",
            "Test Acc:  89.30000066757202\n"
          ]
        }
      ],
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM4hE-PyMsoB",
        "outputId": "203f2fb3-e47d-4ff0-f581-1cbdb92dc73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 28, 100)      2900        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 100)      400         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 28, 250)      25250       batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 250)      1000        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 28, 500)      125500      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 500)      2000        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 528)      0           input_3[0][0]                    \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 14784)        0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 14784)        0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           147850      dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 304,900\n",
            "Trainable params: 303,200\n",
            "Non-trainable params: 1,700\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(100, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(250, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "hid3 = keras.layers.Dense(500, activation='relu')(bat2)\n",
        "bat3 = keras.layers.BatchNormalization()(hid3)\n",
        "concat = keras.layers.Concatenate()([input, bat3])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.5)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9W-FTgxMvOo",
        "outputId": "2de3541f-2344-4e96-bf77-183e53ce7fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 48s 27ms/step - loss: 1.1102 - accuracy: 0.7823 - val_loss: 0.6290 - val_accuracy: 0.8560\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 48s 28ms/step - loss: 0.6593 - accuracy: 0.8432 - val_loss: 0.4245 - val_accuracy: 0.8834\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 48s 28ms/step - loss: 0.5461 - accuracy: 0.8573 - val_loss: 0.4370 - val_accuracy: 0.8666\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.4472 - accuracy: 0.8672 - val_loss: 0.4128 - val_accuracy: 0.8632\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.4182 - accuracy: 0.8731 - val_loss: 0.3688 - val_accuracy: 0.8862\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.3909 - accuracy: 0.8795 - val_loss: 0.3914 - val_accuracy: 0.8748\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 48s 28ms/step - loss: 0.3654 - accuracy: 0.8830 - val_loss: 0.3584 - val_accuracy: 0.8828\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.3398 - accuracy: 0.8904 - val_loss: 0.3391 - val_accuracy: 0.8878\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.3158 - accuracy: 0.8942 - val_loss: 0.3126 - val_accuracy: 0.8934\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2969 - accuracy: 0.8995 - val_loss: 0.3318 - val_accuracy: 0.8912\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 46s 26ms/step - loss: 0.2786 - accuracy: 0.9040 - val_loss: 0.3251 - val_accuracy: 0.8958\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2754 - accuracy: 0.9035 - val_loss: 0.3129 - val_accuracy: 0.8972\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2536 - accuracy: 0.9084 - val_loss: 0.3120 - val_accuracy: 0.8966\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2468 - accuracy: 0.9137 - val_loss: 0.3214 - val_accuracy: 0.8940\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 46s 26ms/step - loss: 0.2257 - accuracy: 0.9184 - val_loss: 0.3049 - val_accuracy: 0.9044\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 45s 26ms/step - loss: 0.2340 - accuracy: 0.9153 - val_loss: 0.3239 - val_accuracy: 0.8988\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 46s 26ms/step - loss: 0.2274 - accuracy: 0.9196 - val_loss: 0.3347 - val_accuracy: 0.8906\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2137 - accuracy: 0.9225 - val_loss: 0.3256 - val_accuracy: 0.9004\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.2084 - accuracy: 0.9245 - val_loss: 0.3485 - val_accuracy: 0.8940\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.2033 - accuracy: 0.9263 - val_loss: 0.3544 - val_accuracy: 0.8960\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.1985 - accuracy: 0.9280 - val_loss: 0.3468 - val_accuracy: 0.8994\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 47s 27ms/step - loss: 0.1870 - accuracy: 0.9330 - val_loss: 0.3672 - val_accuracy: 0.8910\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.1824 - accuracy: 0.9334 - val_loss: 0.3560 - val_accuracy: 0.9000\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 46s 26ms/step - loss: 0.1840 - accuracy: 0.9335 - val_loss: 0.3666 - val_accuracy: 0.9002\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.1764 - accuracy: 0.9365 - val_loss: 0.3572 - val_accuracy: 0.8990\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 45s 26ms/step - loss: 0.1714 - accuracy: 0.9374 - val_loss: 0.3724 - val_accuracy: 0.8998\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 45s 26ms/step - loss: 0.1725 - accuracy: 0.9383 - val_loss: 0.3957 - val_accuracy: 0.8970\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 46s 27ms/step - loss: 0.1751 - accuracy: 0.9390 - val_loss: 0.3859 - val_accuracy: 0.8946\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 45s 26ms/step - loss: 0.1686 - accuracy: 0.9397 - val_loss: 0.3778 - val_accuracy: 0.9030\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 45s 26ms/step - loss: 0.1590 - accuracy: 0.9422 - val_loss: 0.3764 - val_accuracy: 0.9006\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xG2RRgbcMyWj",
        "outputId": "26ffedbe-1914-44c4-98e1-f655e46d9d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Acc:  94.04727220535278\n",
            "Validation Acc:  90.0600016117096\n",
            "Test Acc:  89.77000117301941\n"
          ]
        }
      ],
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_Final_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}